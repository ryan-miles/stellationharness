{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNC1j3jZSkocAXRxr95WMSu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryan-miles/stellationharness/blob/main/SynthSalesDataGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AmOGr9krPfS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install faker"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itLHplXJPhaC",
        "outputId": "3e9b0621-fd1c-49f2-855c-00ed734e3a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.11/dist-packages (37.3.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import json\n",
        "import random\n",
        "from faker import Faker\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "def random_items():\n",
        "    items = []\n",
        "    for _ in range(random.randint(1, 5)):\n",
        "        items.append({\n",
        "            # Increase the number of random characters in the SKU pattern\n",
        "            # This provides a much larger pool of unique values\n",
        "            \"sku\": fake.unique.bothify(text=\"SKU######\"), # Changed from SKU#### to SKU######\n",
        "            \"name\": fake.word().capitalize(),\n",
        "            \"qty\": random.randint(1, 5),\n",
        "            \"price\": round(random.uniform(5, 150), 2)\n",
        "        })\n",
        "    # Clear the unique provider for 'sku' generation after each batch of items.\n",
        "    # This helps prevent the UniquenessException when generating many orders,\n",
        "    # especially if SKUs don't need to be globally unique across ALL orders,\n",
        "    # but rather unique within a large dataset.\n",
        "    # If SKUs MUST be globally unique, consider a much larger pattern or a different approach.\n",
        "    # However, for generating sample data, clearing unique is often sufficient.\n",
        "    fake.unique.clear()\n",
        "    return items\n",
        "\n",
        "def random_payment():\n",
        "    method = random.choice([\"credit_card\", \"paypal\", \"apple_pay\", \"bank_transfer\"])\n",
        "    payment = {\"method\": method}\n",
        "    if method == \"credit_card\":\n",
        "        payment[\"last4\"] = fake.credit_card_number()[-4:]\n",
        "    elif method == \"paypal\":\n",
        "        payment[\"email\"] = fake.email()\n",
        "    elif method == \"bank_transfer\":\n",
        "        payment[\"account\"] = fake.bban()\n",
        "    return payment\n",
        "\n",
        "def random_order():\n",
        "    has_gift = random.choice([True, False])\n",
        "    order = {\n",
        "        # Using a larger pattern for order_id as well, just in case\n",
        "        \"order_id\": fake.unique.bothify(text=\"ORD########\"), # Changed from ORD##### to ORD########\n",
        "        \"customer\": {\n",
        "            # Using a larger pattern for customer_id as well\n",
        "            \"customer_id\": fake.unique.bothify(text=\"CUST######\"), # Changed from CUST#### to CUST######\n",
        "            \"name\": fake.name(),\n",
        "            \"email\": fake.email()\n",
        "        },\n",
        "        \"items\": random_items(),\n",
        "        \"order_date\": (datetime.utcnow() - timedelta(days=random.randint(0, 365))).isoformat() + \"Z\",\n",
        "        \"status\": random.choice([\"processing\", \"shipped\", \"delivered\", \"canceled\"]),\n",
        "        \"shipping_address\": {\n",
        "            \"line1\": fake.street_address(),\n",
        "            \"city\": fake.city(),\n",
        "            \"state\": fake.state_abbr(),\n",
        "            \"zip\": fake.zipcode()\n",
        "        },\n",
        "        \"payment\": random_payment()\n",
        "    }\n",
        "    if has_gift:\n",
        "        order[\"gift_message\"] = fake.sentence()\n",
        "\n",
        "    # Clear the unique provider for order and customer IDs after each order.\n",
        "    # Similar to clearing SKUs, this is useful if global uniqueness across all 20,000 orders\n",
        "    # isn't strictly required for the generated sample data.\n",
        "    fake.unique.clear()\n",
        "    return order\n",
        "\n",
        "\n",
        "def generate_orders(n=1000):\n",
        "    return [random_order() for _ in range(n)]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    orders = generate_orders(20000) # Changed from 1000 to 20000\n",
        "    with open(\"orders.json\", \"w\") as f:\n",
        "        json.dump(orders, f, indent=2)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Rrw8lSj0S12B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "# Define the input and output filenames\n",
        "input_file_path = \"orders.json\"\n",
        "output_file_path = \"10orders.json\"\n",
        "\n",
        "try:\n",
        "    # Open and read the input JSON file\n",
        "    with open(input_file_path, 'r') as infile:\n",
        "        orders_data = json.load(infile)\n",
        "\n",
        "    # Select the top 10 records\n",
        "    top_10_orders = orders_data[:10]\n",
        "\n",
        "    # Open the output file in write mode\n",
        "    with open(output_file_path, 'w') as outfile:\n",
        "        # Write the top 10 orders to the new JSON file\n",
        "        json.dump(top_10_orders, outfile, indent=2)\n",
        "\n",
        "    print(f\"Successfully extracted the top 10 orders and saved to '{output_file_path}'\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The input file '{input_file_path}' was not found. Make sure 'orders.json' exists.\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Error: Could not decode JSON from '{input_file_path}'. Check if the file contains valid JSON.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# The '10orders.json' file is now created with the first 10 records"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgpVgT1gVega",
        "outputId": "0f0c7b50-bc4b-46f3-a4d3-2e595012eac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully extracted the top 10 orders and saved to '10orders.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Define the input and output filenames\n",
        "input_file_path = \"orders.json\"\n",
        "# Change the output file name to reflect the number of orders saved\n",
        "output_file_path = \"10000orders.json\"\n",
        "# Define how many orders to extract\n",
        "num_orders_to_extract = 10000\n",
        "\n",
        "try:\n",
        "    # Open and read the input JSON file\n",
        "    with open(input_file_path, 'r') as infile:\n",
        "        orders_data = json.load(infile)\n",
        "\n",
        "    # Select the top 'num_orders_to_extract' records\n",
        "    # Ensure we don't try to extract more orders than are in the file\n",
        "    top_orders = orders_data[:min(num_orders_to_extract, len(orders_data))]\n",
        "\n",
        "    # Open the output file in write mode\n",
        "    with open(output_file_path, 'w') as outfile:\n",
        "        # Write the selected orders to the new JSON file\n",
        "        json.dump(top_orders, outfile, indent=2)\n",
        "\n",
        "    print(f\"Successfully extracted the top {len(top_orders)} orders and saved to '{output_file_path}'\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The input file '{input_file_path}' was not found. Make sure 'orders.json' exists.\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Error: Could not decode JSON from '{input_file_path}'. Check if the file contains valid JSON.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# The '10000orders.json' file is now created with the first 10,000 (or fewer) records"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXJKtpioWCDx",
        "outputId": "ae0c1154-5b49-41fb-c2de-7f8df34785fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully extracted the top 10000 orders and saved to '10000orders.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "from faker import Faker\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "# Load orders from the new file\n",
        "# Change the input file name\n",
        "with open(\"10000orders.json\") as f:\n",
        "    orders = json.load(f)\n",
        "\n",
        "def random_fulfillment(order):\n",
        "    # Randomly decide to fulfill in 1 or 2 sales\n",
        "    splits = 1 if random.random() < 0.7 else 2\n",
        "    items = order[\"items\"].copy()\n",
        "    fulfilled_batches = []\n",
        "    for _ in range(splits):\n",
        "        if not items:\n",
        "            break\n",
        "        batch = []\n",
        "        for item in items[:]:\n",
        "            # Randomly decide how much of each item is fulfilled in this batch\n",
        "            qty = item[\"qty\"] if splits == 1 else random.randint(1, item[\"qty\"])\n",
        "            batch.append({**item, \"qty\": qty})\n",
        "            # Decrement or remove item\n",
        "            if qty == item[\"qty\"]:\n",
        "                items.remove(item)\n",
        "            else:\n",
        "                item[\"qty\"] -= qty\n",
        "        fulfilled_batches.append(batch)\n",
        "    return fulfilled_batches\n",
        "\n",
        "def random_sale(order, batch, idx):\n",
        "    status = random.choices(\n",
        "        [\"completed\", \"pending\", \"canceled\", \"refunded\"],\n",
        "        weights=[0.8, 0.1, 0.05, 0.05]\n",
        "    )[0]\n",
        "    # Sale date after order date\n",
        "    order_dt = datetime.fromisoformat(order[\"order_date\"].replace(\"Z\", \"\"))\n",
        "    sale_dt = order_dt + timedelta(hours=random.randint(1, 120))\n",
        "    # Amount = sum price * qty for items in this batch\n",
        "    amount = round(sum(item[\"price\"] * item[\"qty\"] for item in batch), 2)\n",
        "    sale = {\n",
        "        \"sale_id\": fake.unique.bothify(text=\"SALE#######\"),\n",
        "        \"order_id\": order[\"order_id\"],\n",
        "        \"customer_id\": order[\"customer\"][\"customer_id\"],\n",
        "        \"sale_date\": sale_dt.isoformat() + \"Z\",\n",
        "        \"fulfilled_items\": batch,\n",
        "        \"sale_amount\": amount,\n",
        "        \"status\": status\n",
        "    }\n",
        "    return sale\n",
        "\n",
        "def generate_sales(orders):\n",
        "    sales = []\n",
        "    for order in orders:\n",
        "        fulfilled_batches = random_fulfillment(order)\n",
        "        for idx, batch in enumerate(fulfilled_batches):\n",
        "            sales.append(random_sale(order, batch, idx))\n",
        "        fake.unique.clear()\n",
        "    return sales\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sales = generate_sales(orders)\n",
        "    with open(\"sales.json\", \"w\") as f:\n",
        "        json.dump(sales, f, indent=2)"
      ],
      "metadata": {
        "id": "5C28sRLNYA86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "from faker import Faker\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "# Load orders and sales\n",
        "with open(\"orders.json\") as f:\n",
        "    orders = json.load(f)\n",
        "with open(\"sales.json\") as f:\n",
        "    sales = json.load(f)\n",
        "\n",
        "def pick_carrier():\n",
        "    return random.choice([\"UPS\", \"FedEx\", \"USPS\", \"DHL\", \"Amazon Logistics\"])\n",
        "\n",
        "def random_shipment(sale):\n",
        "    # Randomly choose to ship all or part of sale\n",
        "    shipped_items = []\n",
        "    for item in sale[\"fulfilled_items\"]:\n",
        "        max_qty = item[\"qty\"]\n",
        "        shipped_qty = random.randint(1, max_qty)\n",
        "        shipped_items.append({**item, \"qty\": shipped_qty})\n",
        "    status = random.choices(\n",
        "        [\"shipped\", \"in_transit\", \"delivered\", \"delayed\", \"lost\", \"returned\"],\n",
        "        weights=[0.4, 0.3, 0.2, 0.05, 0.025, 0.025]\n",
        "    )[0]\n",
        "    shipment_date = datetime.fromisoformat(sale[\"sale_date\"].replace(\"Z\", \"\")) + timedelta(hours=random.randint(2, 72))\n",
        "    shipment = {\n",
        "        \"shipment_id\": fake.unique.bothify(text=\"SHIP#######\"),\n",
        "        \"order_id\": sale[\"order_id\"],\n",
        "        \"sale_id\": sale[\"sale_id\"],\n",
        "        \"shipment_date\": shipment_date.isoformat() + \"Z\",\n",
        "        \"carrier\": pick_carrier(),\n",
        "        \"tracking_number\": fake.bothify(text=\"1Z#######US\"),\n",
        "        \"status\": status,\n",
        "        \"shipped_items\": shipped_items\n",
        "    }\n",
        "    return shipment\n",
        "\n",
        "def generate_shipments(sales):\n",
        "    shipments = []\n",
        "    for sale in sales:\n",
        "        # Some sales may result in more than one shipment, simulating split shipments\n",
        "        num_shipments = 1 if random.random() < 0.85 else 2\n",
        "        for _ in range(num_shipments):\n",
        "            shipments.append(random_shipment(sale))\n",
        "        fake.unique.clear()\n",
        "    return shipments\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    shipments = generate_shipments(sales)\n",
        "    with open(\"shipments.json\", \"w\") as f:\n",
        "        json.dump(shipments, f, indent=2)\n"
      ],
      "metadata": {
        "id": "Ak-R-t9WZbfs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}